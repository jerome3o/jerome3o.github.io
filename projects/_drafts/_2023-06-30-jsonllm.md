---
layout: post
title: "JsonLLM: Getting Open Source LLMs to follow some rules"
---

## The Motivation

I currently work in Aerospace, specifically in rocket launch services. This industry is [heavily regulated](https://cloud.google.com/security/compliance/itar) and a lot of knowledge is strictly export controlled, which means using a tool like GitHub Copilot is out of the question.

Having experienced the AI productivity boost at home, I desperately tried to get an open source on-prem Copilot-like service like [FauxPilot](https://github.com/fauxpilot/fauxpilot) or [Tabby](https://www.tabbyml.com/) running on-site. This worked with varying degrees of success, however with the compute available I wasn't able to get anything nearly as good as Copilot.

I did however end up getting my hands dirty with some open source LLMs - and became particularly interested in running private on-prem agents, like a real sci-fi AI personal assistant. I wanted something that could read my emails, and edit my calendar, and maybe in the future plan whole events and buy things on my behalf. I wanted it to be all on prem, self hosted, so that all my data stays on-site. Also I think if AI is going to be running a large part of my life I'd like to know how it all works, and be running the majority of it myself.

## The Problem

Open source models have approximate knowledge of many things, and are *reasonably* smart when pushed in the right directions. I found they can get the jist of what I wanted, but when you actually get down to trying to produce structured parsable text to build function arguments from, it was particularly flakey.

For example, I want it to be able to read an email, and put events in my calendar. A naive way to do this would be to write a python script that scans for new emails, and on each email prompt the AI with something like (note this is using completion, not chat):

```python
prompt = """\
Content of an email:
{email_content}

List of calendar events in JSON format like \{"title": "title_string", "date": "dd-mm-yyyy"\}:
""".format(email_content=email_content)
```

And then have some smart python code to parse the JSON, validate the values, and pass them to a python function that calls the Gmail API. This is prone to many formatting, parsing, and validation issues, like it might get the date wrong, hallucinate extra fields, or not even return the desired json at all.

GPT-4 could probably do it easily, but the open source models I can run (like Vicuna 13B) would have a hard time doing it reliably. Also as you start doing more complicated stuff, even GPT-4 struggles.

The fundamental idea here is that you are relying on the LLM to understand the *format* you want the data in (JSON), as well as the idea you want it to produce (new calendar events). The former is very strict, grammatical, and can be defined programmatically, and the latter is purely semantic in the realm of natural language understanding, which is the magic that these LLMs are useful for.

## The Solution

There are many ways to tackle this problem, here are some potential solutions
* Use a better LLM, GPT-4 produces very reliable outputs
* Use prompt engineering and make some smart chained LLM calls
* Prune tokens at generation time so that only tokens adhering to your specification are selected

Seeing as I wanted to do everything on prem, and don't want to buy an 8xA100 rig for my little home server, using bigger models was not a viable option.

The prompt engineering route is likely to have varying reliability between models, as some prompt engineering tricks may differ in efficacy between LLMs.

The third option is a bit more complicated but would provide the reliability I was after. And depending on how it was implemented could be very versatile.

And because it would be able to guarantee a given structure, I could make it produce JSON objects that follow a provided jsonschema. That alongside pydantics ability to provide jsonschema for a model, I should be able to create a very pythonic/pydantic interface to the text generation. For example, following the calendar theme from before I should be able to do something like:

```python
model = load_llm()

class CalendarEvent(BaseModel):
    start_time: datetime
    end_time: datetime
    title: str

result = generate_json_from_schema(
    prompt="define a calendar event in json starting at... etc",
    schema=CalendarEvent.schema(),
    model=model,
)

calendar_event = CalendarEvent(**result)
```

Or similar, in this case `generate_json_from_schema` is a function returning a parsed json object from the guided model generation.

Before jumping into the details let's take a quick overview of how LLMs generate text

## LLM Refresher

Maybe get ChatGPT to write this part

* summary of structure
    * prompt
    * tokenised
    * embedded
    * multi attention heads + feed forward blocks
    * big feed forward network
    * softmax, to get probs for next token
    * sample from that prob dist somehow
* top k, top p, sampling, beam, etc
* discussion of how json LLM prunes tokens

# The Implementation

## Prior Art

* Jsonformer
* ReLLM
* ParserLLM
* OpenAI functions (not sure how it works)

## JsonLLM Implementation

JsonLLM leverages ParserLLM heavily, it takes in a JsonSchema, converts it to a context free grammar, and then hands the generation over to ParserLLM.

This isolated the complexity to a translation between two schemas. I'm unsure if I'll be able to represent all the jsonschema features in context free grammars, but so far I've been able to quickly implement enough to be useful (objects, lists, strings, numbers, booleans). And adding new features should be relatively straightforward, by just adding to/adjusting the jsonschema to CFG script.


# Misc Learnings

* partial regex matching in the regex library
* finding appropriate stopping criteria for regex matching
* logit processor in transformers
* speed up by not generating constant regex values

* Prior art of token masking (ReLLM, ParserLLM, jsonformer)


* Discussion of jsonllm
    * Converts jsonschema into cfg


    * Uses lark to make a parser



    * Hands that over to ParserLLM



    * Which breaks it down into regular expressions and leverages ReLLM.


* Link to code and some examples (with a nice pydantic code snippet)
