---
layout: post
title: "Gaussian Splatting: Fun with WebGL"
---

# Gaussian Splatting

I've been playing around with some Gaussian Splats!

## Context

[Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting) is a new novel way of turning a point cloud into a beautifully rendered 3D scene. I'm definitely not an expert on this, but here is my understanding so far.

Gaussian Splatting is a form of [Neural Radiance Field](https://www.matthewtancik.com/nerf)s (NeRF) however they have some core differences/novel aspects:

* They represent the volume in a scene with a collection of 3D gaussian distributions (a.k.a. splats) with colour and alpha values.
* They use neat tricks for rasterising the scene that allows for much faster rendering
* The properties of each gaussian (variance in each direction, colour, and alpha values) are trainable parameters, and are trained against the original videos

The faster rasterisation technique means that the outputs can be rendered at real time frame rates (and the training is super fast too!).

## My process for creating splats

A friend from work shared some youtube videos with me about what they are and how they make them ([here](https://www.youtube.com/watch?v=kShNYOuDnlI&ab_channel=TheNeRFGuru) and [here](https://www.youtube.com/watch?v=HVv_IQKlafQ&ab_channel=IndividualKex)) and I had to try it out for myself.

I was able to get some simple renders up and running in an afternoon (testament to the training speed and code quality of the researchers!). Here is an outline of my process

Note: be warned - this is very scrappy and thrown together, I've spent most of my time playing around recording stuff

### Setup

My hardware/software setup:

* OS: Ubuntu 22.04
* GPU: RTX4090
* RAM: 16gb
* CPU: Intel(R) Core(TM) i5-9600KF CPU @ 3.70GHz (time for an upgrade...)

You'll need to clone [Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting), and follow their install/setup requirements.

I had a bit of trouble installing the correct CUDA runtime, however `sudo apt install cuda-11-6` was how I got it in the end (after following [this](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html) most of the way).

I also needed `conda` and `ffmpeg`.

### Record a Video

When recording a scene you want to splat, I generally get about 2mins of footage circling the objects of interest 2-3 times, trying to get the biggest range of perspectives possible. I try to get high/low/mid angle shots at close-ish range, and then also try and get a view from reasonably far away (2-3m).

This is a big area for experimentation. It's very GIGO - so try out a few and see what works.

### `ffmpeg` to Get the Frames

I then use `ffmpeg` to convert the videos into frames. I try and end up with about ~400 images because that seems to complete processing in a reasonable amount of time and doesn't run into VRAM issues on my RTX4090 (I'm sure there are a bunch of optimisations that could be done to really squeeze out that VRAM).

The magical `ffmpeg` incantation is:

```bash
FILE_NAME=your_file_name
FPS=desired fps

ffmpeg -i $FILE_NAME -qscale:v 1 -qmin 1 -vf fps=$FPS %04d.jpg
```

For each video I do a little calculation to figure out what FPS to use to make sure I sit at about 400 images. Based of The NeRF Guru's amazing [video](https://www.youtube.com/watch?v=UXtuigy_wYc). A lot of great stuff in that video - but it's all for Windows so I ended up skipping a lot of the setup stuff.

That script will create a bunch of jpg's in the current directory - in order for the next steps to work you're going to need the data in a folder like this:

```
~/path/to/data/dir/
    inputs/
        0001.jpg
        0002.jpg
        ...
    original_video.mp4
```

I use this little script to set that up for me:

```sh
DATA_DIR=data/SCENE_NAME
FILE_PATH=~/from/phone/video_name.mp4
FPS=6

FILE_NAME=$(basename $FILE_PATH)

# create the directory
mkdir -p $DATA_DIR
cp $FILE_PATH $DATA_DIR

(
    cd $DATA_DIR
    ffmpeg -i $FILE_NAME -qscale:v 1 -qmin 1 -vf fps=$FPS %04d.jpg
    mkdir input
    mv *.jpg input
)
```

### Gaussian Splatting Scripts

The [Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting) repository contains two scripts:

* `convert.py`
* `train.py`

With the project conda environment activated, from the repository root, I run this script:

```sh
python convert.py -s $DATA_DIR
python train.py -s $DATA_DIR
```

If I run out of VRAM, I will adjust these parameters for `train.py`:

* Increase these values:
    * `--densify_grad_threshold`, starts at `0.0002`
    * `--densification_interval`, starts at `100`
* Decrease this value:
    * `--densify_until_iter`, starts at `15_000`

This has worked to varying degrees of success (YMMV).

### View the result!

There will be an output/ directory in the gaussian splatting repository root with the outputs for your splat, the folder names are hashes so I just sort by modified to find the latest.

You want to find the `point_cloud/iteration_30000/point_cloud.ply` file (`iteration_7000` is also often quite good).

Then I use [this awesome project](https://github.com/antimatter15/splat) that uses WebGL to render gaussian splatting scenes in your browser to view the splats!

All you have to do is go to an instance of the renderer (they provide one [here](https://antimatter15.com/splat/)) and drag your `point_cloud.ply` file into the window.

## Results

Here are a few of my renders so far!

* [A cherry blossom outside our house](/demos/splats/?url=data/cherry_one.splat)
* [Some plants on our coffee table (ft. my flatmate)](/demos/splats/?url=data/board.splat)
* [Olivia in our front yard](/demos/splats/?url=data/liv.splat) (didn't really work well, but still interesting)
