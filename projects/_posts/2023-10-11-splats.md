---
layout: post
title: "Gaussian Splatting"
---

# Gaussian Splatting

I've been playing around with some Gaussian Splats! Before I go into the what and how, have a look at the gallery so far

## Gallery

**Click on the images to enter an interactive viewer**

### Rocket Lab's Electron Rocket (F36) at LC-1 in Mahia

Footage by [James Rattray](https://www.linkedin.com/in/james-rattray-823270a9/)

<a href="/demos/splats/?url=data/electron_lc1.splat"><img src="/projects/assets/splat/electron_lc1.png"/></a>

### Sisyphus

Sculpture by Francis Upritchard, [Chrischurch Art Gallery Description](https://christchurchartgallery.org.nz/exhibitions/francis-upritchard-paper-creature-stone) (couldn't find one from Auckland Art Gallery, where I saw it). Splat recorded at [Auckland Art Gallery](https://www.aucklandartgallery.com/).

<a href="/demos/splats/?url=data/sisyphus.splat"><img src="/projects/assets/splat/sisyphus.png"/></a>

### Koedal Baydham Adhaz Parw (Crocodile Shark) Mask

Sculpture by Alick Tipoti, [National Gallery of Australia Description](https://digital.nga.gov.au/archive/exhibition/undisclosed/default.cfm%3Firn=199788&bioartistirn=4751&mystartrow=25&realstartrow=25&mnuid=srch&viewid=2.html). Splat recorded at [Auckland Art Gallery](https://www.aucklandartgallery.com/).

<a href="/demos/splats/?url=data/shark.splat"><img src="/projects/assets/splat/shark.png"/></a>

### A Quiver of Names

Sculpture by Zac Langdon-Pole, [Auckland Art Gallery Description](https://www.aucklandartgallery.com/explore-art-and-ideas/artwork/37773/a-quiver-of-names). Splat recorded at [Auckland Art Gallery](https://www.aucklandartgallery.com/).

<a href="/demos/splats/?url=data/quiver.splat"><img src="/projects/assets/splat/quiver.png"/></a>

### Albert Park Pavilion, ft. Liv

<a href="/demos/splats/?url=data/pavilion.splat"><img src="/projects/assets/splat/pavilion.png"/></a>

### Still Life at Auckland Art Gallery

Works by Len Castle, Pat Perrin, Tom Kreisler, and Isobel Thom. For more detailed attribution see [this](/projects/assets/splat/pottery_attribution.png). Splat recorded at [Auckland Art Gallery](https://www.aucklandartgallery.com/).

<a href="/demos/splats/?url=data/pottery.splat"><img src="/projects/assets/splat/pottery.png"/></a>

### Batik Cloth, Ever Present: First Peoples Art of Australia

Unfortunately I couldn't find detailed attribution online, but you can read more [here](https://www.nationalgallery.sg/everpresent).

<a href="/demos/splats/?url=data/sheets.splat"><img src="/projects/assets/splat/sheets.png"/></a>

### A cherry blossom outside our house

<a href="/demos/splats/?url=data/cherry_one.splat"><img src="/projects/assets/splat/cherry.png"/></a>

### Some plants on our coffee table (ft. my flatmate)

<a href="/demos/splats/?url=data/alex.splat"><img src="/projects/assets/splat/alex.png"/></a>

### Olivia in our front yard

This one didn't really work, but it's still interesting

<a href="/demos/splats/?url=data/liv.splat"><img src="/projects/assets/splat/liv.png"/></a>

### Will on a hit an run spree

<a href="/demos/splats/?url=data/bike.splat"><img src="/projects/assets/splat/bike.png"/></a>

### Greissen's car

This was originally to help her sell the car online, but the render probably wont persuade any buyer

<a href="/demos/splats/?url=data/gcar.splat"><img src="/projects/assets/splat/gcar.png"/></a>


## Context

[Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting) is a new novel way of turning a point cloud into a beautifully rendered 3D scene. I'm definitely not an expert on this, but here is my understanding so far.

Gaussian Splatting is a form of [Neural Radiance Field](https://www.matthewtancik.com/nerf)s (NeRF) however they have some core differences/novel aspects:

* They represent the volume in a scene with a collection of 3D gaussian distributions (a.k.a. splats) with colour and alpha values.
* They use neat tricks for rasterising the scene that allows for much faster rendering
* The properties of each gaussian (variance in each direction, colour, and alpha values) are trainable parameters, and are trained against the original videos

The faster rasterisation technique means that the outputs can be rendered at real time frame rates (and the training is super fast too!).

## My process for creating splats

**NOTE**: I have since containerised the process and built it into a [Dagster](https://dagster.io/) job. My code is WIP, but can be found [here](https://github.com/jerome3o/splatting)

A friend from work shared some youtube videos with me about what they are and how they make them ([here](https://www.youtube.com/watch?v=kShNYOuDnlI&ab_channel=TheNeRFGuru) and [here](https://www.youtube.com/watch?v=HVv_IQKlafQ&ab_channel=IndividualKex)) and I had to try it out for myself.

I was able to get some simple renders up and running in an afternoon (testament to the training speed and code quality of the researchers!). Here is an outline of my processh. Be warned - this is very scrappy and thrown together, I've spent most of my time playing around recording stuff

### Setup

My hardware/software setup:

* OS: Ubuntu 22.04
* GPU: RTX4090
* RAM: 16gb
* CPU: Intel(R) Core(TM) i5-9600KF CPU @ 3.70GHz (time for an upgrade...)
* Camera: Samsung S22 Rear ultra wide camera (12MP)

You'll need to clone [Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting), and follow their install/setup requirements.

I had a bit of trouble installing the correct CUDA runtime, however `sudo apt install cuda-11-6` was how I got it in the end (after following [this](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html) most of the way).

I also needed `conda` and `ffmpeg`.

### Record a Video

When recording a scene you want to splat, I generally get about 2mins of footage circling the objects of interest 2-3 times, trying to get the biggest range of perspectives possible. I try to get high/low/mid angle shots at close-ish range, and then also try and get a view from reasonably far away (2-3m).

This is a big area for experimentation. It's very GIGO - so try out a few and see what works.

### `ffmpeg` to Get the Frames

I then use `ffmpeg` to convert the videos into frames. I try and end up with about ~400 images because that seems to complete processing in a reasonable amount of time and doesn't run into VRAM issues on my RTX4090 (I'm sure there are a bunch of optimisations that could be done to really squeeze out that VRAM).

The magical `ffmpeg` incantation is:

```bash
FILE_NAME=your_file_name
FPS=desired fps

ffmpeg -i $FILE_NAME -qscale:v 1 -qmin 1 -vf fps=$FPS %04d.jpg
```

For each video I do a little calculation to figure out what FPS to use to make sure I sit at about 400 images. Based of The NeRF Guru's amazing [video](https://www.youtube.com/watch?v=UXtuigy_wYc). A lot of great stuff in that video - but it's all for Windows so I ended up skipping a lot of the setup stuff.

That script will create a bunch of jpg's in the current directory - in order for the next steps to work you're going to need the data in a folder like this:

```
~/path/to/data/dir/
    inputs/
        0001.jpg
        0002.jpg
        ...
    original_video.mp4
```

I use this little script to set that up for me:

```sh
DATA_DIR=data/SCENE_NAME
FILE_PATH=~/from/phone/video_name.mp4
FPS=6

FILE_NAME=$(basename $FILE_PATH)

# create the directory
mkdir -p $DATA_DIR
cp $FILE_PATH $DATA_DIR

(
    cd $DATA_DIR
    ffmpeg -i $FILE_NAME -qscale:v 1 -qmin 1 -vf fps=$FPS %04d.jpg
    mkdir input
    mv *.jpg input
)
```

### Gaussian Splatting Scripts

The [Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting) repository contains two scripts:

* `convert.py`
* `train.py`

With the project conda environment activated, from the repository root, I run this script:

```sh
python convert.py -s $DATA_DIR
python train.py -s $DATA_DIR
```

If I run out of VRAM, I will adjust these parameters for `train.py`:

* Increase these values:
    * `--densify_grad_threshold`, starts at `0.0002`
    * `--densification_interval`, starts at `100`
* Decrease this value:
    * `--densify_until_iter`, starts at `15_000`

This has worked to varying degrees of success (YMMV).

### View the result!

There will be an output/ directory in the gaussian splatting repository root with the outputs for your splat, the folder names are hashes so I just sort by modified to find the latest.

You want to find the `point_cloud/iteration_30000/point_cloud.ply` file (`iteration_7000` is also often quite good).

Then I use [this awesome project](https://github.com/antimatter15/splat) that uses WebGL to render gaussian splatting scenes in your browser to view the splats!

All you have to do is go to an instance of the renderer (they provide one [here](https://antimatter15.com/splat/)) and drag your `point_cloud.ply` file into the window.
